package com.example.vap_back.kafka;

import com.example.vap_back.dto.NewsCrawlEvent;
import com.example.vap_back.service.NewsRedisService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

import java.util.List;
import java.util.Map;

@Slf4j
@Component
@RequiredArgsConstructor
public class NewsCrawlConsumer {

    private final NewsRedisService newsRedisService;

    @KafkaListener(topics = "crawl-news", groupId = "news-crawler-group")
    public void consume(NewsCrawlEvent event) {

        String category = event.getCategory();

        // ğŸ”’ ì¤‘ë³µ í¬ë¡¤ë§ ë°©ì§€
        if (newsRedisService.isCrawling(category)) {
            return;
        }

        try {
            newsRedisService.markCrawling(category);

            // ğŸ”¥ ì—¬ê¸°ì„œ ì‹¤ì œ í¬ë¡¤ë§ ìˆ˜í–‰
            List<Map<String, Object>> articles =
                    /* ê¸°ì¡´ í¬ë¡¤ë§ ë¡œì§ í˜¸ì¶œ */ List.of();

            newsRedisService.crawlAndSave(category, articles);

            log.info("ë‰´ìŠ¤ ê°±ì‹  ì™„ë£Œ - category={}", category);

        } catch (Exception e) {
            log.error("ë‰´ìŠ¤ ê°±ì‹  ì‹¤íŒ¨ - category={}", category, e);
        } finally {
            newsRedisService.clearCrawling(category);
        }
    }
}
